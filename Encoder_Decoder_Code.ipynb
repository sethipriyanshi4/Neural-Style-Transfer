{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "301vg1sRA14E",
        "outputId": "da051455-b54d-4be9-8ded-42dfb78af092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_harr_wav(in_channels, pool=True):\n",
        "\n",
        "    \"\"\"wavelet decomposition using conv2d\n",
        "    Defining the 4 harr wavelet kernels which when\n",
        "    used for pooling results in 4 channels. Dim of the\n",
        "    four kerns are al 2x2 kernel matrices.\n",
        "\n",
        "    \"\"\"\n",
        "    harr_wav_L = 1 / np.sqrt(2) * np.ones((1, 2))\n",
        "    harr_wav_H = 1 / np.sqrt(2) * np.ones((1, 2))\n",
        "    harr_wav_H[0][0] = - harr_wav_H[0][0]\n",
        "\n",
        "    harr_wav_LL = (harr_wav_L).T * harr_wav_L\n",
        "    harr_wav_LH = (harr_wav_L).T * harr_wav_H\n",
        "    harr_wav_HL = (harr_wav_H).T * harr_wav_L\n",
        "    harr_wav_HH = (harr_wav_H).T * harr_wav_H\n",
        "\n",
        "    #prepare the layers for the convolution\n",
        "    filter_LL = torch.from_numpy(harr_wav_LL).unsqueeze(0)\n",
        "    filter_LH = torch.from_numpy(harr_wav_LH).unsqueeze(0)\n",
        "    filter_HL = torch.from_numpy(harr_wav_HL).unsqueeze(0)\n",
        "    filter_HH = torch.from_numpy(harr_wav_HH).unsqueeze(0)\n",
        "\n",
        "    #if it is pooling using wavelet transform - use convolution\n",
        "    #if it is unpooling using wavelet transform - use component wise transposed convolution\n",
        "    if pool:\n",
        "        net = nn.Conv2d\n",
        "    else:\n",
        "        net = nn.ConvTranspose2d\n",
        "\n",
        "    #define the layers such that each channel is convolved individually for each of the 4 kernels\n",
        "    LL = net(in_channels, in_channels,\n",
        "             kernel_size=2, stride=2, padding=0, bias=False,\n",
        "             groups=in_channels)\n",
        "    LH = net(in_channels, in_channels,\n",
        "             kernel_size=2, stride=2, padding=0, bias=False,\n",
        "             groups=in_channels)\n",
        "    HL = net(in_channels, in_channels,\n",
        "             kernel_size=2, stride=2, padding=0, bias=False,\n",
        "             groups=in_channels)\n",
        "    HH = net(in_channels, in_channels,\n",
        "             kernel_size=2, stride=2, padding=0, bias=False,\n",
        "             groups=in_channels)\n",
        "\n",
        "    LL.weight.requires_grad = False\n",
        "    LH.weight.requires_grad = False\n",
        "    HL.weight.requires_grad = False\n",
        "    HH.weight.requires_grad = False\n",
        "\n",
        "    LL.weight.data = filter_LL.float().unsqueeze(0).expand(in_channels, -1, -1, -1)\n",
        "    LH.weight.data = filter_LH.float().unsqueeze(0).expand(in_channels, -1, -1, -1)\n",
        "    HL.weight.data = filter_HL.float().unsqueeze(0).expand(in_channels, -1, -1, -1)\n",
        "    HH.weight.data = filter_HH.float().unsqueeze(0).expand(in_channels, -1, -1, -1)\n",
        "\n",
        "    return LL, LH, HL, HH"
      ],
      "metadata": {
        "id": "U5aQaT0iA3VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WavePool(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(WavePool, self).__init__()\n",
        "        self.LL, self.LH, self.HL, self.HH = get_harr_wav(in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.LL(x), self.LH(x), self.HL(x), self.HH(x)"
      ],
      "metadata": {
        "id": "tIGpqw_1BL6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WaveUnpool(nn.Module):\n",
        "    def __init__(self, in_channels, option_unpool='cat5'):\n",
        "        super(WaveUnpool, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.option_unpool = option_unpool\n",
        "        self.LL, self.LH, self.HL, self.HH = get_harr_wav(self.in_channels, pool=False)\n",
        "\n",
        "    def forward(self, LL, LH, HL, HH, original=None):\n",
        "        if self.option_unpool == 'sum':\n",
        "            return self.LL(LL) + self.LH(LH) + self.HL(HL) + self.HH(HH)\n",
        "        elif self.option_unpool == 'cat5' and original is not None:\n",
        "            return torch.cat([self.LL(LL), self.LH(LH), self.HL(HL), self.HH(HH), original], dim=1)\n",
        "        else:\n",
        "            raise NotImplementedError"
      ],
      "metadata": {
        "id": "pBIxQYnTBPPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from harr import WavePool,WaveUnpool"
      ],
      "metadata": {
        "id": "5ecjr6CxBvQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class WaveEncoder(nn.Module):\n",
        "    def __init__(self, option_unpool):\n",
        "        super(WaveEncoder, self).__init__()\n",
        "        self.option_unpool = option_unpool\n",
        "\n",
        "        self.pad = nn.ReflectionPad2d(1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv0 = nn.Conv2d(3, 3, 1, 1, 0)\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, 1, 0)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, 1, 0)\n",
        "        self.pool1 = WavePool(64)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, 1, 0)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, 1, 0)\n",
        "        self.pool2 = WavePool(128)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, 1, 0)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.conv3_4 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.pool3 = WavePool(256)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, 1, 0)"
      ],
      "metadata": {
        "id": "jNM9XYPSDJyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "        skips = {}\n",
        "        for level in [1, 2, 3, 4]:\n",
        "            x = self.encode(x, skips, level)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2JZ-r9pfDPG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "     def encode(self, x, skips, level):\n",
        "        assert level in {1, 2, 3, 4}\n",
        "        if self.option_unpool == 'sum':\n",
        "            if level == 1:\n",
        "                out = self.conv0(x)\n",
        "                out = self.relu(self.conv1_1(self.pad(out)))\n",
        "                out = self.relu(self.conv1_2(self.pad(out)))\n",
        "                skips['conv1_2'] = out\n",
        "                LL, LH, HL, HH = self.pool1(out)\n",
        "                skips['pool1'] = [LH, HL, HH]\n",
        "                return LL\n",
        "            elif level == 2:\n",
        "                out = self.relu(self.conv2_1(self.pad(x)))\n",
        "                out = self.relu(self.conv2_2(self.pad(out)))\n",
        "                skips['conv2_2'] = out\n",
        "                LL, LH, HL, HH = self.pool2(out)\n",
        "                skips['pool2'] = [LH, HL, HH]\n",
        "                return LL\n",
        "            elif level == 3:\n",
        "                out = self.relu(self.conv3_1(self.pad(x)))\n",
        "                out = self.relu(self.conv3_2(self.pad(out)))\n",
        "                out = self.relu(self.conv3_3(self.pad(out)))\n",
        "                out = self.relu(self.conv3_4(self.pad(out)))\n",
        "                skips['conv3_4'] = out\n",
        "                LL, LH, HL, HH = self.pool3(out)\n",
        "                skips['pool3'] = [LH, HL, HH]\n",
        "                return LL\n",
        "            else:\n",
        "                return self.relu(self.conv4_1(self.pad(x)))\n",
        "\n",
        "        elif self.option_unpool == 'cat5':\n",
        "            if level == 1:\n",
        "                out = self.conv0(x)\n",
        "                out = self.relu(self.conv1_1(self.pad(out)))\n",
        "                return out\n",
        "\n",
        "            elif level == 2:\n",
        "                out = self.relu(self.conv1_2(self.pad(x)))\n",
        "                skips['conv1_2'] = out\n",
        "                LL, LH, HL, HH = self.pool1(out)\n",
        "                skips['pool1'] = [LH, HL, HH]\n",
        "                out = self.relu(self.conv2_1(self.pad(LL)))\n",
        "                return out\n",
        "\n",
        "            elif level == 3:\n",
        "                out = self.relu(self.conv2_2(self.pad(x)))\n",
        "                skips['conv2_2'] = out\n",
        "                LL, LH, HL, HH = self.pool2(out)\n",
        "                skips['pool2'] = [LH, HL, HH]\n",
        "                out = self.relu(self.conv3_1(self.pad(LL)))\n",
        "                return out\n",
        "\n",
        "            else:\n",
        "                out = self.relu(self.conv3_2(self.pad(x)))\n",
        "                out = self.relu(self.conv3_3(self.pad(out)))\n",
        "                out = self.relu(self.conv3_4(self.pad(out)))\n",
        "                skips['conv3_4'] = out\n",
        "                LL, LH, HL, HH = self.pool3(out)\n",
        "                skips['pool3'] = [LH, HL, HH]\n",
        "                out = self.relu(self.conv4_1(self.pad(LL)))\n",
        "                return out\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "BTJ_ql-XDSCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class WaveDecoder(nn.Module):\n",
        "    def __init__(self, option_unpool):\n",
        "        super(WaveDecoder, self).__init__()\n",
        "        self.option_unpool = option_unpool\n",
        "\n",
        "        if option_unpool == 'sum':\n",
        "            multiply_in = 1\n",
        "        elif option_unpool == 'cat5':\n",
        "            multiply_in = 5\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.pad = nn.ReflectionPad2d(1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv4_1 = nn.Conv2d(512, 256, 3, 1, 0)\n",
        "\n",
        "        self.recon_block3 = WaveUnpool(256, option_unpool)\n",
        "        if option_unpool == 'sum':\n",
        "            self.conv3_4 = nn.Conv2d(256*multiply_in, 256, 3, 1, 0)\n",
        "        else:\n",
        "            self.conv3_4_2 = nn.Conv2d(256*multiply_in, 256, 3, 1, 0)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 0)\n",
        "        self.conv3_1 = nn.Conv2d(256, 128, 3, 1, 0)\n",
        "\n",
        "        self.recon_block2 = WaveUnpool(128, option_unpool)\n",
        "        if option_unpool == 'sum':\n",
        "            self.conv2_2 = nn.Conv2d(128*multiply_in, 128, 3, 1, 0)\n",
        "        else:\n",
        "            self.conv2_2_2 = nn.Conv2d(128*multiply_in, 128, 3, 1, 0)\n",
        "        self.conv2_1 = nn.Conv2d(128, 64, 3, 1, 0)\n",
        "\n",
        "        self.recon_block1 = WaveUnpool(64, option_unpool)\n",
        "        if option_unpool == 'sum':\n",
        "            self.conv1_2 = nn.Conv2d(64*multiply_in, 64, 3, 1, 0)\n",
        "        else:\n",
        "            self.conv1_2_2 = nn.Conv2d(64*multiply_in, 64, 3, 1, 0)\n",
        "        self.conv1_1 = nn.Conv2d(64, 3, 3, 1, 0)"
      ],
      "metadata": {
        "id": "zRhUrbh8DybK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x, skips):\n",
        "        for level in [4, 3, 2, 1]:\n",
        "            x = self.decode(x, skips, level)\n",
        "        return"
      ],
      "metadata": {
        "id": "uDO_Pwn1D2Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def decode(self, x, skips, level):\n",
        "        assert level in {4, 3, 2, 1}\n",
        "        if level == 4:\n",
        "            out = self.relu(self.conv4_1(self.pad(x)))\n",
        "            LH, HL, HH = skips['pool3']\n",
        "            original = skips['conv3_4'] if 'conv3_4' in skips.keys() else None\n",
        "            out = self.recon_block3(out, LH, HL, HH, original)\n",
        "            _conv3_4 = self.conv3_4 if self.option_unpool == 'sum' else self.conv3_4_2\n",
        "            out = self.relu(_conv3_4(self.pad(out)))\n",
        "            out = self.relu(self.conv3_3(self.pad(out)))\n",
        "            return self.relu(self.conv3_2(self.pad(out)))\n",
        "        elif level == 3:\n",
        "            out = self.relu(self.conv3_1(self.pad(x)))\n",
        "            LH, HL, HH = skips['pool2']\n",
        "            original = skips['conv2_2'] if 'conv2_2' in skips.keys() else None\n",
        "            out = self.recon_block2(out, LH, HL, HH, original)\n",
        "            _conv2_2 = self.conv2_2 if self.option_unpool == 'sum' else self.conv2_2_2\n",
        "            return self.relu(_conv2_2(self.pad(out)))\n",
        "        elif level == 2:\n",
        "            out = self.relu(self.conv2_1(self.pad(x)))\n",
        "            LH, HL, HH = skips['pool1']\n",
        "            original = skips['conv1_2'] if 'conv1_2' in skips.keys() else None\n",
        "            out = self.recon_block1(out, LH, HL, HH, original)\n",
        "            _conv1_2 = self.conv1_2 if self.option_unpool == 'sum' else self.conv1_2_2\n",
        "            return self.relu(_conv1_2(self.pad(out)))\n",
        "        else:\n",
        "            return self.conv1_1(self.pad(x))"
      ],
      "metadata": {
        "id": "2xIr46tiDXfV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}